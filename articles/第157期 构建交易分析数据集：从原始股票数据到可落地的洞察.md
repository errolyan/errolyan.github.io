# 第157期 构建交易分析数据集：从原始股票数据到可落地的洞察


![](https://fastly.jsdelivr.net/gh/bucketio/img0@main/2025/10/24/1761315914775-fdce1bcf-f115-4ed2-9a7e-998338063689.png)

每位量化交易者都会面临同一个问题：你有了一个想法、一个假设，甚至可能是关于市场行为的突破性见解。

但现实很快会给你泼一盆冷水：数据在哪里？该如何构建数据结构？哪种格式最适合机器学习、回测和模式识别？

接下来，我将向你展示如何构建一个可投入生产的数据集，该数据集能捕捉最关键的市场波动，且可支持你后续想要进行的任何分析。

## 🎯 我们要构建的数据集
一个综合性数据集，主要追踪以下内容：
- 开盘动量（交易的前30分钟）
- 收盘动量（交易的后30分钟）
- 次日相关性（今日收盘价能否预测次日走势？）
- 模式分类（动量、反转、消退、弱势）

所有数据均经过清洗和结构化处理，可直接用于：
- 机器学习模型 🤖
- 统计分析 📊
- 交易策略回测 💹
- 模式挖掘算法 🔍

## 完整流程

### 步骤1：数据获取——收集原始数据 📥
构建数据集的基础是实现灵活的数据获取功能，具体代码如下：
```python
def get_stock_data(ticker, start_date, end_date, frequency='1d'):
```

该函数的重要性在于，它能生成你所需的两类数据流：
1. **日度数据**——用于长期模式分析和次日走势预测
   ```python
   aapl_daily = get_stock_data('AAPL', '2024-01-01', '2024-12-31', '1d')
   ```
2. **30分钟级日内数据**——用于开盘/收盘动量分析
   ```python
   aapl_30min = get_stock_data('AAPL', '2024-01-01', '2024-12-31', '30m')
   ```

该函数会自动完成以下操作：
- 处理时区标准化（对跨市场分析至关重要）
- 移除空值（避免数据缺失带来的麻烦）
- 添加“Price_Change（价格变动）”列（这是核心指标）
- 将所有数据格式化为保留2位小数（确保精度一致）

函数输出结果如下：

| 日期       | 开盘价 | 最高价 | 最低价 | 收盘价 | 成交量   | 价格变动 |
| ---------- | ------ | ------ | ------ | ------ | -------- | -------- |
| 2024-01-02 | 185.58 | 186.86 | 182.35 | 184.08 | 82488700 | -1.50    |
| 2024-01-03 | 182.67 | 184.32 | 181.89 | 182.70 | 58414500 | 0.03     |

数据干净、结构清晰，可直接与其他数据集合并使用 ✅

#### 日度数据：
==================================================
| 日期                                               | 开盘价 | 最高价 | 最低价 | 收盘价 | 成交量   | 价格变动 |
| -------------------------------------------------- | ------ | ------ | ------ | ------ | -------- | -------- |
| 2024-01-02                                         | 185.58 | 186.86 | 182.35 | 184.08 | 82488700 | -1.50    |
| 2024-01-03                                         | 182.67 | 184.32 | 181.89 | 182.70 | 58414500 | 0.03     |
| 2024-01-04                                         | 180.62 | 181.55 | 179.36 | 180.38 | 71983600 | -0.24    |
| 2024-01-05                                         | 180.46 | 181.23 | 178.66 | 179.66 | 62379700 | -0.80    |
| 2024-01-08                                         | 180.56 | 184.04 | 179.98 | 184.00 | 59144500 | 3.44     |
| 2024-01-09                                         | 182.38 | 183.60 | 181.20 | 183.59 | 42841800 | 1.21     |
| 数据维度：(6, 6)                                   |        |        |        |        |          |          |
| ================================================== |        |        |        |        |          |          |

#### 30分钟级数据：
==================================================
注：日内数据仅限最近60天，此处使用2025年8月9日至2025年10月7日的数据
| 时间                | 开盘价 | 最高价 | 最低价 | 收盘价 | 成交量   | 价格变动 |
| ------------------- | ------ | ------ | ------ | ------ | -------- | -------- |
| 2025-08-11 13:30:00 | 226.75 | 228.73 | 224.76 | 226.04 | 11810798 | -0.71    |
| 2025-08-11 14:00:00 | 226.04 | 227.30 | 225.84 | 226.77 | 4347976  | 0.73     |
| 2025-08-11 14:30:00 | 226.79 | 227.89 | 226.49 | 226.52 | 3335854  | -0.27    |
| 2025-08-11 15:00:00 | 226.52 | 227.65 | 226.10 | 227.47 | 4642000  | 0.95     |
| 2025-08-11 15:30:00 | 227.47 | 228.96 | 227.47 | 228.62 | 4044485  | 1.15     |
| ...                 | ...    | ...    | ...    | ...    | ...      | ...      |

### 步骤2：特征工程——创建信号列 🔧
原始数据只是一堆数字，而特征才是洞察的来源。以下是关键函数：
```python
def show_half_hour_changes(data, frequency):
```

该函数能将日内数据转换为特征矩阵，具体说明如下：
- 输入：数百个30分钟时间区间的数据
- 输出：包含模式分类的结构化日度特征

特征矩阵的构建代码如下：
```python
changes_df = pd.DataFrame({
    'Date': first_half_hour.index,  # 日期
    'First_Open': first_half_hour['Open'],  # 开盘30分钟的开盘价
    'First_Close': first_half_hour['Close'],  # 开盘30分钟的收盘价
    'First_Change': first_half_hour['Price_Change'],  # 开盘30分钟的价格变动
    'First_Change_%': percentage_calculation,  # 开盘30分钟的价格变动百分比
    'Last_Open': last_half_hour['Open'],  # 收盘30分钟的开盘价
    'Last_Close': last_half_hour['Close'],  # 收盘30分钟的收盘价
    'Last_Change': last_half_hour['Price_Change'],  # 收盘30分钟的价格变动
    'Last_Change_%': percentage_calculation  # 收盘30分钟的价格变动百分比
})
```

模式分类逻辑如下：
```python
if first_change > 0 and last_change > 0:
    pattern = "Strong Day"        # 开盘、收盘30分钟均上涨→强势日（动量延续）
elif first_change > 0 and last_change < 0:
    pattern = "Fade Day"          # 开盘30分钟上涨、收盘30分钟下跌→消退日（动能耗尽）
elif first_change < 0 and last_change > 0:
    pattern = "Recovery Day"      # 开盘30分钟下跌、收盘30分钟上涨→复苏日（走势反转）
else:
    pattern = "Weak Day"          # 开盘、收盘30分钟均下跌→弱势日（弱势延续）
```

这一分类的重要意义在于：你从此拥有了带标签的训练数据，可直接用于监督学习 🎓

特征工程后的输出数据集如下：

| 日期       | 开盘30分钟 |            | 收盘30分钟 |            | 当日模式 |
| ---------- | ---------- | ---------- | ---------- | ---------- | -------- |
|            | 价格变动   | 变动百分比 | 价格变动   | 变动百分比 |          |
| 2025-08-11 | $ -0.71    | -0.3%      | $ -0.45    | -0.2%      | 弱势日   |
| 2025-08-12 | $ -0.13    | -0.1%      | $ +0.48    | +0.2%      | 复苏日   |
| 2025-08-13 | $ +0.26    | +0.1%      | $ -0.26    | -0.1%      | 消退日   |

每一行都是一个可直接用于分析的特征向量 🎯

### 步骤3：相关性数据集——构建预测层 🔮
对交易而言，最有价值的数据集是能关联“因”与“果”的数据集。以下是核心函数：
```python
def show_last_half_hour_next_day_changes(data_30min, data_daily):
```

该函数通过合并以下两类数据，构建时间相关性矩阵：
- 当日收盘30分钟的走势
- 次日全天的表现

数据合并逻辑如下：
```python
for date, last_row in last_half_hour.iterrows():
    current_date = pd.to_datetime(date)
    next_date = current_date + timedelta(days=1)

    # 查找次日数据（跳过周末）
    next_day_data = data_daily[data_daily['date'] == next_date.date()]

    if not next_day_data.empty:
        next_day_row = next_day_data.iloc[0]
        merged_data.append({
            'Date': date,  # 当日日期
            'Last_30min_Close': last_row['Close'],  # 当日收盘30分钟的收盘价
            'Last_30min_Change': last_row['Price_Change'],  # 当日收盘30分钟的价格变动
            'Last_30min_Change_%': (last_row['Price_Change'] / last_row['Open'] * 100) if last_row['Open'] != 0 else 0,  # 当日收盘30分钟的价格变动百分比
            'Next_Day_Open': next_day_row['Open'],  # 次日开盘价
            'Next_Day_Close': next_day_row['Close'],  # 次日收盘价
            'Next_Day_Change_%': next_day_row['Next_Day_Change']  # 次日价格变动百分比
        })
```

上述循环会生成包含以下信息的复合记录：
- 第N天收盘30分钟的数据
- 第N+1天全天的表现数据


![](https://fastly.jsdelivr.net/gh/bucketio/img2@main/2025/10/24/1761315934689-0dca7ce4-b036-4bc9-ad80-004148c6cc2c.png)


用于预测建模的模式分类逻辑如下：
```python
if last_change > 0 and next_day_pct > 0:
    pattern = "Momentum Continues ↗️"   # 当日收盘上涨且次日上涨→动量延续（正自相关）
elif last_change > 0 and next_day_pct < 0:
    pattern = "Momentum Fades ↘️"       # 当日收盘上涨但次日下跌→动量消退（均值回归）
elif last_change < 0 and next_day_pct > 0:
    pattern = "Reversal Next Day ↗️"    # 当日收盘下跌但次日上涨→次日反转（超卖反弹）
else:
    pattern = "Weakness Continues ↘️"   # 当日收盘下跌且次日下跌→弱势延续（负动量）
```

最终输出数据集如下：

| 日期       | 当日收盘30分钟 |            | 次日表现   |          | 模式       |
| ---------- | -------------- | ---------- | ---------- | -------- | ---------- |
|            | 价格变动       | 变动百分比 | 变动百分比 | 收盘价   |            |
| 2025-08-11 | $ -0.45        | -0.2%      | +1.6%      | $ 229.65 | 次日反转 ↗️ |
| 2025-08-12 | $ +0.48        | +0.2%      | -0.2%      | $ 233.33 | 动量消退 ↘️ |
| 2025-08-13 | $ -0.26        | -0.1%      | -0.5%      | $ 232.78 | 弱势延续 ↘️ |

这个数据集对机器学习而言堪称“黄金资源”：每个模式都是一个标签，每个百分比都是一个特征，每一行都是一个训练样本 💎

## 统计摘要：内置分析指标
这段代码不仅能生成数据集，还能提供即时洞察，具体实现如下：
```python
print(f"模式摘要:")
print(f"  动量延续:  {count}/{total} 天 ({percentage:.1f}%)")
print(f"  动量消退:  {count}/{total} 天 ({percentage:.1f}%)")
print(f"  次日反转:  {count}/{total} 天 ({percentage:.1f}%)")
print(f"  弱势延续:  {count}/{total} 天 ({percentage:.1f}%)")
```

### 输出结果
==========================================================================
**模式摘要：**
- 动量延续：31天中有10天（32.3%）
- 动量消退：31天中有9天（29.0%）
- 次日反转：31天中有5天（16.1%）
- 弱势延续：31天中有7天（22.6%）

通过这一分布，你可以了解：
- 哪些模式最为常见
- 市场中是动量效应还是均值回归效应占主导
- 你所关注的交易领域是否存在可利用的模式

## 数据集的使用方式

### 用于机器学习
```python
# 特征：当日收盘30分钟的价格变动、变动百分比
X = correlation_data[['Last_30min_Change', 'Last_30min_Change_%']]

# 目标变量：次日走势方向（上涨/下跌）
y = (correlation_data['Next_Day_Change_%'] > 0).astype(int)

# 训练模型
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X, y)
```

### 用于回测 💹
```python
# 模拟策略：当日弱势收盘时买入，次日卖出
strategy_returns = []
for _, row in correlation_data.iterrows():
    if row['Last_30min_Change'] < -0.5:  # 弱势收盘（价格变动小于-0.5）
        strategy_returns.append(row['Next_Day_Change_%'])
```

### 用于模式挖掘 🔍
```python
# 筛选出动量强势延续的所有日期
strong_momentum = correlation_data[
    (correlation_data['Last_30min_Change_%'] > 0.5) &  # 当日收盘30分钟变动百分比大于0.5%
    (correlation_data['Next_Day_Change_%'] > 1.0)     # 次日变动百分比大于1.0%
]
```

### 用于统计分析
```python
# 计算相关系数
correlation = correlation_data['Last_30min_Change_%'].corr(
    correlation_data['Next_Day_Change_%']  # 当日收盘30分钟变动百分比与次日变动百分比的相关性
)
```

## 💾 导出数据集以进行进一步分析
这个流程的一大优势在于：所有数据最终都以pandas DataFrame格式呈现，因此你可以将其导出为任何格式，具体如下：
```python
# 导出为CSV格式，用于Excel、R或其他工具
changes_df.to_csv('intraday_patterns.csv', index=False)

# 导出为JSON格式，用于Web应用
correlation_data.to_json('correlation_dataset.json', orient='records')

# 导出为Parquet格式，用于大数据管道
changes_df.to_parquet('trading_features.parquet')

# 导出到SQL数据库，用于生产环境
from sqlalchemy import create_engine
engine = create_engine('sqlite:///trading_data.db')
correlation_data.to_sql('momentum_patterns', engine, if_exists='replace')
```

## 🔗 获取完整代码
准备好构建你自己的交易数据集了吗？

👉 完整的Google Colab笔记本链接：
https://colab.research.google.com/drive/1t6rEg1yFbXm2IjQ0TvbdQFiunb0Rj8Ev

在这个笔记本中，你将找到：
- ✅ 本文提到的所有函数
- ✅ 基于苹果（AAPL）股票的可运行示例
- ✅ 用于验证结果的样本输出
- ✅ 可修改以适配任何股票代码的灵活性
- ✅ 易于扩展以添加新特征的结构

只需点击链接，点击“全部运行”，即可开始探索 🎯

## 🎓 该数据集的特别之处
1. **时间结构完整保留**  
   数据集维持了时间序列的完整性，这对避免回测中的前瞻偏差至关重要。

2. **多时间框架融合**  
   将日内信号（30分钟级）与日度结果相结合，同时捕捉微观和宏观市场行为。

3. **预标注模式**  
   已完成模式分类，无需手动标注即可直接用于监督学习。

4. **可直接投入生产的格式**  
   数据干净、经过标准化处理、无缺失值，可直接输入模型使用。

5. **可扩展的架构**  
   如果你想添加相对强弱指数（RSI）、移动平均线或成交量分析等特征，该数据结构能轻松支持。