# 第179期 在生产环境运行AI智能体花了4.7万元：关于A2A和MCP，那些没人会告诉你的事


多智能体系统是未来的发展方向。智能体间（A2A）通信以及Anthropic公司的模型上下文协议（MCP）具有革命性意义。但有一个代价高达4.7万美元的教训，却没人提及：相关的基础设施层尚未建成，这正让所有人付出巨额成本。

## 4.7万元的警钟
去年，我们团队将一个自认为简单的多智能体系统部署到了生产环境中。这是一个由4个LangChain智能体组成的系统，它们通过A2A协同工作，帮助用户研究市场数据。

- 第1周：API成本127元。一切顺利。
- 第2周：891元。嗯，使用量在增长。
- 第3周：6240元。等等，怎么回事？
- 第4周：18400元。开始恐慌。

最终损失：在我们终于停止系统运行前，总花费已达4.7万美元。

罪魁祸首是什么？两个智能体陷入了无限对话循环。这种循环持续了11天——在我们睡觉时、工作时，以及我们以为“系统正平稳运行”的时候，它一直在持续。

这就是2025年多智能体系统的现状。

我们需要正视这个问题。

## 为何多智能体系统势不可挡（以及为何这令人担忧）
单一AI模型已触碰到瓶颈。GPT-4、Claude、Gemini这些模型固然强大，但它们都属于通用型模型。而现实世界中的问题，需要专业型智能体协同解决。

![pSsA3Y](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/pSsA3Y.png)

这种转变已然发生：
- AutoGPT开创了自主智能体的先河
- LangChain让智能体框架变得易于使用
- CrewAI推广了基于角色的智能体团队模式
- OpenAI刚刚发布了用于智能体编排的Swarm
- Anthropic推出了MCP，以实现上下文标准化

但令人不安的事实是：所有人都在未打地基的情况下，就急于建造房屋（喻指在缺乏基础设施支撑的情况下开发多智能体系统）。

## 什么是智能体间（A2A）通信？（通俗解读）
可以把A2A理解为智能体的“Slack（团队沟通软件）”。

你的智能体需要具备以下能力：
- 互相发送信息
- 共享上下文且不丢失信息
- 协调分工
- 妥善处理故障
- 避免陷入让你损失4.7万元的无限循环

## 理想与现实的差距
你以为A2A的运行状态是这样的：

![ucczoU](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/ucczoU.png)

而生产环境中A2A的实际运行状态却是这样的：

![eY2VwE](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/eY2VwE.png)

## MCP的出现：Anthropic的“我们需要标准”时刻
2024年3月，Anthropic公司表示“不能再这样混乱下去”，并发布了模型上下文协议（MCP）。

可以把MCP比作智能体的“USB-C接口”。在USB-C出现之前，每种设备都有不同的充电器，使用体验堪称噩梦；而有了USB-C之后，一根线就能适配所有设备。

### MCP出现之前
![w5hBSh](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/w5hBSh.png)

### MCP出现之后
![bLRmh3](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/bLRmh3.png)

## 30秒了解MCP
```json
{
  "name": "company_knowledge_base",
  "description": "Search internal docs（搜索内部文档）",
  "capabilities": {
    "resources": ["read", "search"],
    "tools": ["semantic_search", "keyword_search"]
  }
}
```
就是这么简单。你的智能体现在可以访问整个知识库，无需自定义代码，无需手动进行提示词工程，直接就能用。

## 黄金组合：A2A + MCP
当智能体既能互相通信（借助A2A），又能访问所需的任何上下文（借助MCP）时，神奇的事情就会发生：

![7SIdVM](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/7SIdVM.png)

### 实际案例：
```python
from crewai import Agent, Task, Crew
from mcp import MCPClient

# MCP为智能体赋予强大能力
mcp = MCPClient(servers=[
    "mcp://sales-db.company.com",  # 销售数据库
    "mcp://knowledge-base.company.com",  # 知识库
    "mcp://analytics.company.com"  # 分析工具
])
# 智能体通过A2A协同工作
sales_agent = Agent(
    role="Sales Analyst（销售分析师）",
    goal="Pull Q4 sales data（提取第四季度销售数据）",
    context_protocol=mcp,
    tools=mcp.get_tools("sales_*")  # 获取销售相关工具
)
research_agent = Agent(
    role="Market Researcher（市场研究员）", 
    goal="Find competitor data（获取竞争对手数据）",
    context_protocol=mcp,
    tools=mcp.get_tools("web_*")  # 获取网络相关工具
)
analyst_agent = Agent(
    role="Strategic Analyst（战略分析师）",
    goal="Compare and synthesize（对比与整合数据）",
    context_protocol=mcp
)
# 智能体团队协同工作
crew = Crew(
    agents=[sales_agent, research_agent, analyst_agent],
    tasks=[sales_task, research_task, analysis_task],
    process="sequential"  # 按顺序执行（A2A协同方式）
)
result = crew.kickoff()  # 启动智能体团队
```
你只需30行代码，就能搭建一个可访问3个不同数据源的三智能体系统。

这在五年前是完全不可能实现的。

## 问题所在：生产环境是梦想的“葬身之地”
你已经打造出了多智能体的杰作，本地测试完美无缺，你准备好改变世界了。

然后你将它部署到了生产环境。


## 生产环境中的七大灾难（基于真实案例）
### 1. 无限循环（损失4.7万美元）
```
# 智能体A向智能体B请求帮助
# 智能体B向智能体A请求进一步说明  
# 智能体A向智能体B请求帮助
# 智能体B向智能体A请求进一步说明
# 【11天后】
# 你的AWS账单到了
```

### 2. 上下文截断
智能体A：“用户想预订5月15日飞往巴黎、5月22日返程的商务舱靠窗座位……”

[MCP上下文达到令牌限制]
智能体B收到的信息：“用户想预订飞往”
智能体B：“预订飞往……哪里的航班？”

### 3. 级联故障
![Zqe8Nq](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/Zqe8Nq.png)

### 4. 隐形故障
```python
# 看似智能体已成功运行！
print("Task completed（任务完成）")

# 实际情况：
actual_result = agent.output
# actual_result = "I apologize, but I couldn't complete that task 
#                  due to insufficient context...（抱歉，由于上下文不足，我无法完成该任务……）"
# 没人发现问题，因为没人查看智能体的输出结果
```

### 5. 令牌激增
预期：每次请求使用1000个令牌
实际：每次请求使用45000个令牌

原因：智能体每次都会将完整文档加载到上下文中
成本：每天1350美元，而非预期的30美元

### 6. 协同死锁
![LuZJMr](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/LuZJMr.png)

### 7. “在我电脑上能正常运行”
- 本地环境：响应时间500毫秒
- 测试环境：响应时间800毫秒  
- 生产环境：响应时间47秒（用户纷纷流失）

原因：你只有1台MCP服务器，却有1000个智能体同时访问，服务器已不堪重负。

## 关于多智能体基础设施的残酷真相
让我来告诉你，在生产环境中运行智能体实际需要哪些条件：
![BQrLPK](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/BQrLPK.png)

没人谈论这些，是因为大多数人还没有大规模部署过智能体。

但他们很快就会这样做，而且会付出高昂的代价才明白这些道理。

## 智能体基础设施应有的样子（但目前尚未实现）
想象一下，部署多智能体系统可以像这样简单：
```
$ git push origin main（代码提交命令）

✓ 检测到：LangChain多智能体系统
✓ 发现：4个支持A2A协同的智能体
✓ 已识别MCP服务器：3台
✓ 正在构建优化容器……
✓ 正在设置消息队列……
✓ 正在配置成本限制……
✓ 正在启用对话追踪……
已部署至：https://your-agent.prod.com
控制台地址：https://dashboard.prod.com
   - 智能体健康状态：良好
   - A2A延迟：平均120毫秒
   - 令牌使用量：0（暂无流量）
   - 今日花费：0.00美元
```

之后还能实时监控：

![sNQFoC](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/sNQFoC.png)

并接收智能警报：
```
警报：智能体B响应时间上升
    当前：450毫秒（为基准值的3倍）
    可能原因：MCP服务器过载
    建议：启用上下文缓存
    
提示：您目前每天使用15000个令牌进行文档查询
    启用缓存后预计每月可节省：140美元
    是否启用？[是/否]
```

这正是我们需要的，但目前尚未实现。

## 基础设施差距（可视化呈现）
Web开发者之所以能对基础设施不以为意，是因为相关问题20年前就已解决。

而智能体开发者还停留在“2005年”，所有配置都需要手动完成。

## 现实架构：如今需要付出什么
经历了4.7万美元的灾难后，我们不能再简单重新部署并心存侥幸。

我花了6周时间，从零开始搭建合适的基础设施。不是我想这么做，而是别无选择。

以下是为了让智能体在生产环境中安全运行，我必须手动配置、连接并维护的每一个组件：

![t7Rt7t](https://raw.githubusercontent.com/errolyan/tuchuang/master/uPic/t7Rt7t.png)

- 搭建时间：我人生中再也回不来的6周
- 基础设施代码量：约3500行（没有一行是用于构建智能体实际功能的）
- 月成本：约800美元（还未运行任何智能体）

而本应有的流程其实很简单：只需执行`git push origin main`（代码提交命令）。

## 即将到来的浪潮
未来12个月，将会发生以下变化：

按回车键或点击即可查看完整尺寸图片

我们正处于“4.7万美元账单刷屏”的阶段。

基础设施层即将成为AI技术栈中最重要的部分。

## 我们在GetOnStack正在构建的东西
我们花了4.7万美元才明白这些道理，就是为了让你不必重蹈覆辙。

我们正在专门为多智能体系统构建生产环境基础设施，具备以下功能：

### 一键部署
```
$ npx getonstack deploy（部署命令）

正在分析代码仓库……
   ✓ 框架：LangChain
   ✓ 检测到智能体数量：4个
   ✓ A2A协同：支持
   ✓ MCP服务器：2台
   
正在构建基础设施……
   ✓ 消息队列已配置
   ✓ 上下文缓存已启用
   ✓ 成本限制已设置（每日100美元）
   ✓ 监控已激活
   
已部署至生产环境！
   网址：https://agent-xyz.getonstack.app
   控制台：https://dash.getonstack.app
   
状态：
   智能体：4/4健康
   A2A延迟：85毫秒
   MCP缓存命中率：0%（正在预热）
   今日花费：0.00美元
```

### 实时可观测性
按回车键或点击即可查看完整尺寸图片

### 内置防护措施
```python
# 自动防护配置
safeguards = {
    "max_cost_per_day": 100,          # 每日成本上限
    "max_tokens_per_request": 10000,  # 防止令牌激增
    "max_loop_iterations": 10,        # 阻止无限循环
    "timeout_per_agent": 30,          # 防止智能体挂起
    "alert_at_threshold": 0.8,        # 阈值预警（达到上限80%时提醒）
}

# 实时成本追踪（API请求示例）
GET /api/costs/realtime
{
    "spent_today": 47.32,  # 今日已花费
    "limit": 100.00,       # 每日上限
    "projection_eod": 68.50,  # 预计当日总花费
    "status": "healthy"    # 状态：健康
}
```

## 加入私人测试版
我们正邀请50个团队参与平台共建。

如果你的项目基于以下技术构建，欢迎加入：
- LangChain多智能体系统
- CrewAI智能体团队
- 自定义A2A架构
- MCP集成

我们将为你提供：
- 几分钟内完成生产环境部署
- 规避4.7万美元级别的错误
- 实现无故障扩展
- 让你能安心睡个好觉

申请早期访问 →

你将获得：
- 专属上线指导
- 直接的技术支持
- 对产品路线图的影响力
- 终身优惠定价

## 未来属于多智能体系统，基础设施必须跟上
A2A通信正在实现专业智能体间的协同。

MCP正在标准化智能体访问上下文和工具的方式。

但如果没有可用于生产环境的基础设施，我们所做的一切都如同在沙子上建摩天大楼。

未来12个月，将决定谁能在智能体基础设施领域占据领先地位。

问题不在于“我是否需要这个”。

而在于“我是要花4.7万元才明白这个道理，还是选择更简单的方式”。