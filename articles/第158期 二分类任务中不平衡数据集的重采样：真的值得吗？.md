# 第158期 二分类任务中不平衡数据集的重采样：真的值得吗？

类别不平衡在二分类的许多实际应用中都很常见，例如罕见疾病筛查、欺诈检测、贷款违约预测以及执法领域（如预测空运/海运货物中的非法内容）等场景。当其中一个类别（如负类）的样本数量远多于另一个类别（如正类）时，就会出现类别不平衡问题。以信用卡欺诈交易为例，正类（欺诈交易）在数据中所占比例可能不足0.1%。在这种情况下，分类器往往会偏向多数类，通常只需大部分时间预测多数类，就能实现较高的总体准确率。

解决这一问题的一种方法是对少数类进行过采样，或对多数类进行欠采样。过采样通过随机复制少数类样本使数据重新平衡，而欠采样则是随机删除部分多数类样本。

对少数类进行过采样能保留所有原始数据，但代价是会产生原本不存在的重复数据点，且不会为少数类引入真正的新信息。此外，如果少数类中包含噪声样本或标签错误的样本，过采样会复制并放大这些误差。过采样还会增加过拟合的风险：复制少数类样本可能导致模型（尤其是决策树或基于规则的分类器）死记硬背这些样本。在简单复制样本的随机过采样情况下，模型可能会学习到过于具体的规则，而这些规则无法泛化到新数据。

另一方面，对多数类进行欠采样需要删除部分多数类样本，以重新平衡训练集。在实际操作中，人们可能会随机选择一部分多数类样本（如10%-20%）来降低类别比例。欠采样一个直观的优势是简化性：在更小、更平衡的数据集上训练，通常能加快学习速度（计算量更少、内存占用更低），并让模型有更多机会学习少数类中的模式。虽然会丢弃部分样本，但这能在实际应用中得到一个更轻量化的模型——该模型推理速度更快、存储需求更低，而且其偏差能更好地反映少数类的性能，而非仅仅关注总体准确率。与过采样不同，欠采样不会复制或生成合成样本，因此本质上不会导致过拟合。然而，其代价是数据丢失，因为随机删除多数类样本可能会丢弃潜在的有用信息。最后，数据量减少可能导致模型（尤其是高方差模型）变得不稳定，因为不同的随机欠采样可能会产生差异很大的分类器。

在本文中，我将通过一个基于合成数据集的简单实验，带大家对比不同的重采样策略，并探讨它们在二分类任务中对预测准确率的影响。我旨在回答的问题是：在二分类场景下，对高度不平衡的数据集进行重采样是否值得？同时，我还会强调在应用这些技术和解读结果时需要注意的几个陷阱。如果大家想跟着操作，可以在我的GitHub仓库中找到完整代码。


## 实验设置
首先，我们使用scikit-learn库中的`make_blobs`函数生成一个合成数据集。该数据集在二维特征空间中包含两个簇：一个簇有20万个样本（代表多数类），另一个簇有50个样本（代表少数类）。因此，少数类在数据集中所占比例约为0.025%。我们还可以调整簇的方差以及簇中心之间的距离。

```python
# 簇的方差
sigma_maj = 0.9
sigma_min = 0.35

# 少数类在水平轴上的偏移量

# 合理性检验
# offset_min = 10
# offset_min = 0

offset_min = -2.8
from sklearn.datasets import make_blobs
X_maj, y_maj = make_blobs(n_samples=n_samples_maj, n_features=2, centers=1, cluster_std=sigma_maj, shuffle=True, random_state=RANDOM_STATE)
X_min, y_min = make_blobs(n_samples=n_samples_min, n_features=2, centers=1, cluster_std=sigma_min, shuffle=True, random_state=RANDOM_STATE)
```

需要注意的是，`offset_min`用于控制簇之间的分离程度。我们设置了两种极端情况作为合理性检验：一种是簇之间完全分离（`offset_min = 10`），另一种是少数类簇完全包含在多数类簇内部（`offset_min = 0`）。不过，在我们的实验中，采用的是正类和负类存在大量重叠的场景，如下图1所示。


![](https://fastly.jsdelivr.net/gh/bucketio/img6@main/2025/10/24/1761316561478-013fc3ee-7b56-46fa-865a-31510f34b17a.png)


**图1：原始数据集中多数类和少数类样本的分布**

我们采用分层分割的方式将数据划分为训练集和测试集，以确保少数类在两个集合中的比例与原始数据集一致。

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=RANDOM_STATE)
```

图2展示了划分后的训练集和测试集——我们可以确定少数类在两个集合中都有良好的代表性。


![](https://fastly.jsdelivr.net/gh/bucketio/img1@main/2025/10/24/1761316574827-1fa63477-917b-4809-879d-d117c2ff60e0.png)


**图2：原始训练集和测试集（未进行重采样）**

```python
print("**********************************************************************")
print("训练集大小：", X_train.shape[0])
print("训练集中少数类样本数量：", int(y_train.sum()))
print("**********************************************************************")
print("测试集大小：", X_test.shape[0])
print("测试集中少数类样本数量：", int(y_test.sum()))
print("**********************************************************************")
```

```
**********************************************************************
训练集大小：134033
训练集中少数类样本数量：33
**********************************************************************
测试集大小：66017
测试集中少数类样本数量：17
**********************************************************************
```


### 模型与评估策略
为了评估和对比不同方法，我们在训练和评估模型时将采用以下5种策略：
- **A. 不进行重采样**——使用原始数据
- **B. 对少数类进行随机过采样**
- **C. 对少数类进行SMOTE过采样**（SMOTE：合成少数类过采样技术）
- **D. 对多数类进行欠采样**
- **E. 结合SMOTE与Tomek Links进行重采样**

我们将针对上述每种场景训练并评估随机森林分类器。选择这种模型是因为它为二分类任务提供了良好的基准性能，并且通常比简单模型更能处理类别不平衡问题——不过，除非进行调整（如类别加权），否则它仍可能偏向多数类。但本文不会探讨类别加权这一方面。

我们将训练一个“参考模型”，该模型在复杂度和泛化性能之间达到最佳平衡，以确保不会对训练数据产生过拟合。这个参考模型将用于所有场景，它是通过在原始数据集上对随机森林分类器进行超参数调优得到的。我们采用如下方法进行调优：

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [3, 5, 10, 15],  # 决策树数量
    'max_depth': [2, 3, 4, 5, 6, 7, 8],  # 决策树最大深度
    'min_samples_split': [2, 5, 10, 20],  # 节点分裂所需最小样本数
    'min_samples_leaf': [1, 4, 8, 10, 12],  # 叶子节点最小样本数
    'max_features': ['sqrt', 'log2'],  # 构建树时考虑的特征数量
}

grid = GridSearchCV(
    RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),
    param_grid,
    cv=cv,
    scoring='average_precision',  # 以平均精度为评分指标
    n_jobs=-1
)

start_time = time.time()
grid.fit(X_train, y_train)
print("--- 耗时：%s 秒 ---" % (round(time.time() - start_time, 2)))

print(grid.best_params_)
```

```
-- 耗时：1263.26 秒 ---
{'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 10}
```

将这些超参数代入随机森林分类器后，我们就能得到场景A（不进行重采样）下模型的交叉验证性能：

```python
# 场景A（不进行重采样）
rfA = RandomForestClassifier(
    n_estimators=10,
    max_depth=6,                # 限制树的深度
    min_samples_split=20,        # 节点分裂至少需要20个样本
    min_samples_leaf=8,         # 每个叶子节点至少包含8个样本
    max_features='sqrt',        # 减少树之间的相关性
    random_state=RANDOM_STATE,
    n_jobs=-1
)
# 确保交叉验证的每个折口中，多数类和少数类的比例保持不变
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)

start_time = time.time()
cv_results_rfA = cross_validate(rfA, X_train, y_train, cv=cv, scoring='average_precision', return_train_score=True)
print("--- 耗时：%s 秒 ---" % (round(time.time() - start_time, 2)))

print(f"训练集PR-AUC分数：{cv_results_rfA['train_score']}")
print(f"训练集PR-AUC平均分数：{cv_results_rfA['train_score'].mean():.2f}")
print(f"训练集PR-AUC分数方差：{cv_results_rfA['train_score'].var():.2f}")
print("-" * 30)
print(f"验证集PR-AUC分数：{cv_results_rfA['test_score']}")
print(f"验证集PR-AUC平均分数：{cv_results_rfA['test_score'].mean():.2f}")
print(f"验证集PR-AUC分数方差：{cv_results_rfA['test_score'].var():.2f}")
```

```
-- 耗时：2.69 秒 ---

训练集PR-AUC分数：[0.51331671 0.422199   0.3644862  0.4129504  0.40330925]
训练集PR-AUC平均分数：0.42
训练集PR-AUC分数方差：0.00
------------------------------
验证集PR-AUC分数：[0.06909023 0.33490319 0.0808029  0.08895189 0.20983211]
验证集PR-AUC平均分数：0.16
验证集PR-AUC分数方差：0.01
```

上述训练集和验证集分数是我们的基准——我们将通过对比判断重采样策略是否能改善这些结果。需要注意的是，我们使用**平均精度（average precision）** 来评估模型性能（实际等同于精确率-召回率曲线下面积，即PR-AUC）。该指标非常适合不平衡数据集，因为它能直接衡量模型“找到少数类样本（高召回率）”和“避免假阳性（高精确率）”的能力。高平均精度分数表明模型在“正确识别稀有正类样本而不被多数类淹没”这一核心任务上表现良好。


## 重采样实验与陷阱
在开始重采样实验前，需先明确**陷阱1**：进行重采样时，务必只对**训练集**重采样！这一点至关重要——测试集的作用是模拟模型在生产环境中遇到的数据（生产环境中的数据显然不会经过重采样），因此在划分训练集和测试集后，测试集应保持“原样”，不得修改。忽视这一细节会导致评估分数虚高，但这种性能在真实的未重采样数据上无法复现。


### 1. 随机过采样（场景B）
我们使用`imblearn`库中的`RandomOverSampler`对训练集中的少数类进行随机过采样，设置为“使重采样后的少数类样本数与多数类样本数相等”。

```python
ros = RandomOverSampler(random_state=RANDOM_STATE)
X_train_upsampled, y_train_upsampled = ros.fit_resample(X_train, y_train)

print("**********************************************************************")
print("过采样前训练集大小：", X_train.shape[0])
print("过采样后训练集大小：", X_train_upsampled.shape[0])
print("**********************************************************************")
print("过采样前训练集中少数类样本数：", int(y_train.sum()))
print("过采样后训练集中少数类样本数：", int(y_train_upsampled.sum()))
print("**********************************************************************")
```

```
**********************************************************************
过采样前训练集大小：134033
过采样后训练集大小：268000
**********************************************************************
过采样前训练集中少数类样本数：33
过采样后训练集中少数类样本数：134000
**********************************************************************
```

![](https://fastly.jsdelivr.net/gh/bucketio/img3@main/2025/10/24/1761316602041-11bee530-fc7f-4276-a2df-cc379d0b3a70.png)

**图3：随机过采样后的训练集**

图3与图2（未重采样的训练集）看起来相似，但需注意：此时每个原始少数类样本都被复制了多份，少数类样本数与多数类样本数完全相等——在可视化中，这些复制样本与原始样本重叠，因此从图中难以直接区分。


### 2. SMOTE过采样（场景C）
SMOTE（Synthetic Minority Oversampling Technique，合成少数类过采样技术）不同于简单复制少数类样本，它通过以下步骤为少数类生成**合成新样本**：
1. 随机选择一个少数类样本（记为A）；
2. 在其他少数类样本中找到A的k个最近邻（k为用户设定的参数，`imblearn`中`SMOTE`函数的默认值为k=5）；
3. 随机选择其中一个近邻（记为B），通过线性插值在特征空间中A与B的连线上生成一个合成样本；
4. 重复上述步骤，直到少数类样本数达到目标数量（此处设为与多数类样本数相等）。

我们使用`imblearn`库的`SMOTE`函数对训练集进行过采样：

```python
sm = SMOTE(random_state=RANDOM_STATE)
X_train_SM_upsampled, y_train_SM_upsampled = sm.fit_resample(X_train, y_train)

print("过采样前训练集大小：", X_train.shape[0])
print("过采样后训练集大小：", X_train_SM_upsampled.shape[0])
print("**********************************************************************")
print("过采样前训练集中少数类样本数：", int(y_train.sum()))
print("过采样后训练集中少数类样本数：", int(y_train_SM_upsampled.sum()))
```

```
过采样前训练集大小：134033
过采样后训练集大小：268000
**********************************************************************
过采样前训练集中少数类样本数：33
过采样后训练集中少数类样本数：134000
```

与随机过采样类似，SMOTE过采样后少数类与多数类样本比例为1:1。下图4展示了SMOTE的效果：训练集中出现了原始数据中不存在的新少数类样本。

**图4：SMOTE过采样后的训练集**


### 3. 随机欠采样（场景D）
我们使用`imblearn`库的`RandomUnderSampler`对训练集中的多数类进行随机欠采样，最终得到“少数类与多数类样本数相等”的小型数据集。从下图5可以看出，欠采样后训练集中的两类样本呈现出明显的分离。

```python
rus = RandomUnderSampler(random_state=RANDOM_STATE)
X_train_downsampled, y_train_downsampled = rus.fit_resample(X_train, y_train)

print("欠采样前训练集大小：", X_train.shape[0])
print("欠采样后训练集大小：", X_train_downsampled.shape[0])
print("**********************************************************************")
print("欠采样前训练集中少数类样本数：", int(y_train.sum()))
print("欠采样后训练集中少数类样本数：", int(y_train_downsampled.sum()))
```

```
欠采样前训练集大小：134033
欠采样后训练集大小：66
**********************************************************************
欠采样前训练集中少数类样本数：33
欠采样后训练集中少数类样本数：33
```



### 4. SMOTE + Tomek Links 混合重采样（场景E）
该场景采用“先过采样、后欠采样”的混合策略：首先用SMOTE对少数类进行过采样，再用Tomek Links对多数类进行欠采样。

Tomek Links是一种常用于不平衡二分类的数据清洗方法，用于改善类别平衡和决策边界。它的核心是识别“不同类别样本的最近邻对”——这类样本通常是类别重叠的边界样本。在实际操作中，Tomek Links中的多数类样本常被视为“噪声”或“冗余”样本；删除这些样本不仅能减少类别不平衡，还能让决策边界更清晰。这种策略相比纯欠采样能保留更多多数类数据，同时避免纯过采样的过度复制风险。