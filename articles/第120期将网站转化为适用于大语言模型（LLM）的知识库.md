# 第120期:将网站转化为适用于大语言模型（LLM）的知识库

## 一、引言
我们当下所熟悉的互联网，本质是为人类打造的产物。网页的设计围绕“浏览器呈现效果”展开，配备了菜单、导航栏、图片等元素，以提升人类用户的视觉体验与操作便捷性。

然而，对于大语言模型（LLMs）这类AI系统而言，设计美观与否毫无意义。它们真正关注的是**清晰的结构、简洁的文本，以及有价值的示例**。而目前，互联网上的绝大多数内容，都难以被LLMs有效学习和利用。

这就引出了一个关键问题：  
倘若我们能让网站（或任何知识来源）不仅“对人类友好”，同时也“对AI友好”，会产生怎样的改变？

这正是“LLM化（LLMification）”理念的核心——将知识资源转化为针对大语言模型优化的格式。这一理念的近期灵感，主要来自安德烈·卡帕西（Andrej Karpathy）与杰里米·霍华德（Jeremy Howard）两位专家的观点。


## 二、将知识转化为机器学习素材
安德烈·卡帕西曾在一条推文中设想：每一本教科书都能实现完美的“LLM化”。无需让AI艰难地逐页读取PDF文件，我们完全可以为模型量身打造一套结构化的内容版本。

具体实现流程如下：
1. **内容提取**：将文本、公式、表格等所有信息提取出来，整理为简洁的Markdown格式；
2. **实例转化**：将“已解答示例”转化为有监督微调数据（即“输入→输出”的配对形式）；
3. **习题重构**：将“练习题”转化为强化学习环境（包含“问题→答案”及参考答案解析）；
4. **合成扩展**：将每种题型泛化出无限变体（例如，不同时间点的时钟角度数学题）；
5. **索引存储**：将所有内容存入带有嵌入向量（Embedding）的数据库，方便模型后续检索。


![](https://fastly.jsdelivr.net/gh/bucketio/img8@main/2025/10/01/1759303398554-8a60e7cd-a91c-4ba0-bf7d-d5bc947ed974.png)


最终能实现什么效果？LLM可以像学生一样“学习物理课程”——阅读知识点解析、尝试示例练习、完成课后习题。这一思路不仅适用于教科书，还能推广到任何知识来源。


## 三、通过llms.txt实现访问标准化
杰里米·霍华德近期提出的一个方案，也与“LLM化”理念异曲同工。他在关于“llms.txt”的提案中提出了一个问题：如何从源头让网站更易于被LLM抓取和索引？

在他的方案中，知识来源聚焦于“网站”，而针对LLM的内容转化无需大规模重构，只需遵循一个特定文本文件的标准即可——核心思路与卡帕西的设想高度契合。

就像“robots.txt”文件用于告知搜索引擎“哪些内容可索引”一样，“llms.txt”是一个放置在网站根目录下的简易Markdown文件，主要功能包括：
- 概括网站的核心内容；
- 列出重要页面的规范链接（Canonical Links）；
- 引导AI爬虫（AI Crawler）定位到结构清晰、格式规整的信息。

这种方式无需重新格式化网站所有内容，仅通过一个“轻量级信号”，就能为LLM指明获取有效信息的方向。


![](https://fastly.jsdelivr.net/gh/bucketio/img16@main/2025/10/01/1759303415766-c6ab6924-3c47-41ef-a68e-a36a311c1bb9.png)



## 四、两种理念的对比
尽管卡帕西与霍华德的方案均以“提升内容对AI的友好性”为目标，但二者的侧重点存在明显差异：



核心结论如下：
- 卡帕西的方案聚焦于“转化深度”（让知识内容更适配LLM的学习需求）；
- 霍华德的方案聚焦于“发现广度”（让LLM更高效地找到可利用的知识内容）。

二者并非对立关系，而是互补关系。


## 五、个人网站的LLM化（演示流程）
受上述理念启发，我搭建了一个简易流程，用于实现“个人网站的LLM化”，具体步骤如下：
1. 抓取网站内容（若有sitemap.xml文件，可直接使用该文件）；
2. 提取主要内容，过滤掉导航栏、广告等无关信息；
3. 将提取的内容转化为Markdown格式，确保结构清晰；
4. 按“语义连贯性”将内容拆分为小块，并添加元数据（标题、日期、标题层级等）；
5. 使用sentence-transformers模型为每个内容块生成嵌入向量（Embedding）；
6. 将内容块及其嵌入向量存入FAISS数据库，以支持快速语义搜索；
7. （可选步骤）生成问答（Q&A）对或内容的合成变体；
8. 通过API提供结果服务，支持检索增强生成（RAG）或“网站问答（Ask my site）”等功能。


![](https://fastly.jsdelivr.net/gh/bucketio/img12@main/2025/10/01/1759303443819-c31ed806-3239-4daf-85fb-860ee09cdef0.png)



## 六、为何这一理念至关重要？
原因很简单：网站的“受众”正在发生改变。

- **当下**：网站为人类而建，搜索引擎作为“中间人”，需解析HTML代码才能判断内容的核心价值；
- **未来**：AI系统（如助手、智能体、协同工具）将成为网站的主要受众。它们无法高效解析杂乱的HTML代码，更需要结构规整、经过筛选、机器可读取的知识内容。

将网站进行“LLM化”，能为你解锁以下价值：

### 1. 提升可发现性
你的网站将不再淹没在信息洪流中。由于内容已生成嵌入向量并完成索引，LLM可直接检索到你的观点、示例与解析。

### 2. 实现交互式知识传递
网站不再局限于“静态博客文章”的形式，而是能转化为“实时问答系统”——人类用户与AI智能体均可通过提问，获取结构化的答案。

### 3. 个人品牌成为“数据集”
若你是AI、医学、金融等领域的专家，LLM在学习你网站内容的过程中，会将你对该领域的独特见解融入其推理逻辑。你将成为行业内的“可信信息源”。

### 4. 赋能教育与培训
教程、案例研究、博客文章等内容，可同时作为LLM的学习素材——这与卡帕西“将教科书转化为机器可学习课程”的愿景高度一致。

### 5. 实现“未来适配”
随着llms.txt等标准的普及，以及AI助手对“筛选后知识”的依赖度提升，打造“对LLM友好的网站”，能确保你的内容在互联网的下一阶段依然具备可访问性。

不妨这样理解互联网的演进：
- 第一代互联网：为人类服务；
- 第二代互联网：为人类与搜索引擎服务；
- 第三代互联网：为人类与AI智能体服务。


## 七、结语
你的网站不必局限于“一系列网页”的形式。它完全可以成为一个“活的”、机器可读取的知识库——既能供人类使用，也能被智能体检索，还能让AI学习。


## 参考资料
1. 卡帕西的推文：https://x.com/karpathy/status/1961128638725923119  
2. 杰里米·霍华德关于llms.txt的文章：https://www.answer.ai/posts/2024-09-03-llmstxt.html  
3. 网站LLM化演示的Colab笔记本  