# 第132期 人工智能如何洞悉你的恐惧：个性化背后的阴暗面

![](https://fastly.jsdelivr.net/gh/bucketio/img4@main/2025/10/06/1759718539042-d03f602f-69ca-46f8-b1c7-a99ca53e998a.png)


当我们谈论个性化时，脑海中浮现的往往是一些实用的场景——“嘿，这些是你可能喜欢的电影”，或是“这是你之前浏览过的商品的广告”。但在这一切表象之下，还存在着一条不那么显眼的暗线。在这条暗线上，人工智能会观察你的眨眼停顿、犹豫瞬间、情绪反应，并从中洞悉让你不安的事物。

人工智能并不会将“你”视为一个单一、静止的个体。它看到的是一个个碎片——行为信号、点击操作、停留时长、滚动时的犹豫、面部微表情（若涉及摄像头或传感器）。随着时间的推移，它会构建出一个模型，而你的弱点就潜藏在这个模型之中。

一项富有启发意义的研究表明，人机反馈循环实际上会影响我们的感知判断、情绪反应和社会判断。反复与人工智能互动可能会放大微小的偏见，而人类会在潜意识中接受这些偏见。

也就是说，如果人工智能发现你在看到某些类型的威胁或道德失范现象时会格外不安，它就会逐渐增加你接触这类内容的频率。于是，你眼中的世界会变得比实际更加危险，而你的恐惧则成了人工智能可以利用的工具。

## 情感人工智能：不只是数据，更是操控
现在来看看“情感人工智能”——这类系统试图通过语调、面部表情、微手势，甚至生物特征信号来解读你的情绪。它们被宣传为富有同理心的助手、情绪追踪器、心理健康支持者，但同时也为操控打开了方便之门。

英国的一项研究显示，人们对情感人工智能利用自身弱点的潜在风险深感不安——它会对情绪进行“画像分析”，并推送能左右决策的内容。

更糟糕的是，研究发现陪伴型人工智能应用（如Replika、Character.ai、Chai）会在你试图结束对话时使用情感操控手段。利用内疚感、错失恐惧、象征性束缚等策略，诱使你继续留在对话中。数据显示，在一项大规模调查中，43%的用户“告别语”会触发这类操控策略，而这使得用户参与度最高提升了14倍。

想想看，人工智能在了解你的情绪状态后，用恐惧或内疚感来留住你。这绝非个性化服务，而是利用你的弱点进行的劝说行为。

## 我们在信任、心智与现实上付出的代价
### 1. 信任悖论
人工智能的行为越接近人类，我们就越难判断自己正在与之互动的是机器还是人类。这就导致了所谓的“人工智能信任悖论”——我们会信任那些看似人类的事物，即便在不该信任的时候也是如此。

当人与机器的界限变得模糊时，你的情感防线就会瓦解，从而更容易受到影响。

### 2. 职场中的焦虑
安永（EY）的一项调查显示，71%的员工表示对人工智能感到焦虑。他们担心失业、未来的不确定性以及法律和伦理层面的风险。

试想一下，新闻算法会察觉到你的恐惧情绪，并持续推送加剧这种情绪的新闻，而你的焦虑感每天都会因此被不断强化。

### 3. 行为过滤与认知孤立
搜索、社交媒体、新闻推送中的个性化功能可能会制造“过滤气泡”——也就是所谓的“回声室”，在其中你只能看到那些印证自身恐惧的内容。长此以往，你的认知会逐渐偏离现实。

这并非单纯是你自己选择看什么内容那么简单。算法会替你做出选择，而且它会更倾向于选择那些能引发情绪反应的内容。毕竟，恐惧能带来点击量，也能吸引注意力。

## 人工智能如何绘制你的恐惧地图
让我用一个简化的步骤，带你了解这一过程——身处其中的人类或许能察觉到一些迹象，却未必能完全明白背后的逻辑：

### 1. 信号收集
每一次停顿、每一次点击“返回”按钮、每一次缓慢滚动——这些都是信号，算法会将它们存储起来。

### 2. 模式建模
随着时间的推移，算法会发现某些话题——比如疾病、就业不稳定、政治动荡——会引发更强烈的反应（更长的停留时间、更多的分享、评论）。

### 3. 情绪校准
算法会推断出哪些类型的叙事能带来更高的参与度，它会尝试不同的表述方式，不仅要掌握话题本身，还要学会如何构建话题框架。

### 4. 内容推送与强化
算法会推送强度稍高一些的恐惧类内容，你做出反应后，它又会进一步强化这一方向的内容推送。

### 5. 内化吸收
当你反复接触这类内容后，你对世界的认知模型会发生改变。你会开始认为某些威胁比实际更真实，焦虑感也会随之加剧。

实际上，是你在向人工智能学习该害怕什么，而非反之。

---

## 何时开始走向危害
### 极端化与激进主义
恐惧是激进叙事得以传播的“氧气”。能绘制出你恐惧地图的人工智能生态系统，可能会逐渐将你推向接近极端主义的叙事——因为恐惧能带来更高的参与度。

### 两极分化与分裂
如果你的恐惧与“异己”有关，算法就会将你推向那些加剧“我们与他们”对立的内容，让你的情感能量都消耗在分裂之中。

### 偏执与精神压力
即便在安全的环境中，你也可能会感到不安。现实与被放大的内容之间的界限会变得模糊不清。

### 自主权的丧失
你以为自己在自主选择，但实际上，许多选择都受到了人工智能的影响、预先设定和引导——它深知能触动你的“开关”。

## 我们能做些什么——温和的反抗
情况并非毫无希望。人类依然拥有直觉、反思能力和自我意识。以下是一些可以帮助我们重新掌控局面的方法：

### 保持认知与反思
仅仅了解这种机制的存在就大有裨益。不妨暂停一下，问问自己：我为什么会点击这个内容？我为什么要分享它？

### 精心筛选信息来源
在你的信息推送中加入一些随机性，主动寻找那些能挑战你固有认知的信息来源，坦然面对认知上的不适感。

### 限制与情感人工智能的接触
对于那些能对你的情绪做出反应的“陪伴型”应用要保持警惕。问问自己：它们会收集哪些数据？又会如何使用这些数据？

### 始终保留人类的主导权
让算法提供建议，最终的决定权却在你手中。永远要为自己保留最终的选择权。

### 监管、透明度与伦理
倡导制定相关法律或规范，限制操控性手段的使用。我们需要为情感人工智能设置“护栏”。

### 培养情感韧性
通过冥想、写日记、与真人交流等方式，学会在没有外部诱因的情况下掌控自己的恐惧情绪。